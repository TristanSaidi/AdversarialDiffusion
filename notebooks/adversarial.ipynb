{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from torchvision import datasets\n",
    "from tqdm import tqdm\n",
    "os.chdir('../src')\n",
    "\n",
    "from models.diffusion import Diffusion, CondDiffusion\n",
    "from models.adversary import Adversary, ConditionalAdversary, GuidedAdversary\n",
    "from models.guidance import Guidance\n",
    "from models.unet import Unet\n",
    "from models.condunet import condUnet\n",
    "\n",
    "reverse_transform = transforms.Compose([transforms.Lambda(lambda x: (x+1)/2), transforms.ToPILImage()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('../data/CIFAR10', exist_ok=True)\n",
    "\n",
    "dataset_train = datasets.CIFAR10(\n",
    "        root='../data/CIFAR10',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([transforms.Grayscale(), transforms.CenterCrop(28),transforms.ToTensor()])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Unconditional Diffusion #####\n",
    "\n",
    "model_path = '../outputs/models/fashion_mnist_diffusion_epoch_19.pt'\n",
    "# model params\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps')\n",
    "data_shape = (28, 28)\n",
    "channels = 1\n",
    "dim_mults = (1, 2, 4, )\n",
    "T = 300\n",
    "\n",
    "net = Unet(\n",
    "    dim=data_shape[0],\n",
    "    channels=channels,\n",
    "    dim_mults=dim_mults,\n",
    ")\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "fashion_mnist_diffusion = Diffusion(\n",
    "    model=net,\n",
    "    data_shape=data_shape,\n",
    "    noise_schedule='linear',\n",
    "    T=T,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the adversary\n",
    "adversary = Adversary(\n",
    "    data_shape=data_shape,\n",
    "    diffusion_model=fashion_mnist_diffusion,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample unperturbed image from the adversary\n",
    "x = adversary.sample()\n",
    "plt.imshow(reverse_transform(x[0].cpu()), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample gaussian perturbed image from the adversary\n",
    "perturbed_sample, original_sample = adversary.gaussian_perturb(t=150)\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(perturbed_sample[0].cpu()), cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(original_sample[0].cpu()), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_target = next(iter(dataset_train))[0].unsqueeze(0).to(device)\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(adversarial_target[0].cpu()), cmap='gray')\n",
    "perturbed_sample, original_sample = adversary.gradient_perturb(t=150, target=adversarial_target)\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(perturbed_sample[0].cpu()), cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(original_sample[0].cpu()), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_target = next(iter(dataset_train))[0].unsqueeze(0).to(device)\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(adversarial_target[0].cpu()), cmap='gray')\n",
    "perturbed_sample, original_sample = adversary.gradient_descent_perturb(t=50, target=adversarial_target, scale=5)\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(perturbed_sample[0].cpu()), cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(original_sample[0].cpu()), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Conditional Diffusion #####\n",
    "\n",
    "model_path = '../outputs/models/cond_fashion_mnist_diffusion_linear_sched_epoch_19.pt'\n",
    "\n",
    "# model params\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "data_shape = (28, 28)\n",
    "channels = 1\n",
    "dim_mults = (1, 2, 4, )\n",
    "T = 300\n",
    "\n",
    "net = condUnet(\n",
    "    dim=data_shape[0],\n",
    "    channels=channels,\n",
    "    dim_mults=dim_mults,\n",
    "    num_classes=10,\n",
    ")\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "fashion_mnist_cond_diffusion = CondDiffusion(\n",
    "    model=net,\n",
    "    data_shape=data_shape,\n",
    "    noise_schedule='linear',\n",
    "    T=T,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the adversary\n",
    "adversary = ConditionalAdversary(\n",
    "    data_shape=data_shape,\n",
    "    diffusion_model=fashion_mnist_cond_diffusion,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample unperturbed image from the adversary\n",
    "y = torch.tensor([0]).to(device)\n",
    "y_adv = torch.tensor([1]).to(device)\n",
    "x = adversary.sample(y)\n",
    "plt.imshow(reverse_transform(x[0].cpu()), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample gaussian perturbed image from the adversary\n",
    "perturbed_sample, original_sample = adversary.gaussian_perturb(t=150, y=y)\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(perturbed_sample[0].cpu()), cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(original_sample[0].cpu()), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_target = adversary.sample(y_adv)\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(adversarial_target[0].cpu()), cmap='gray')\n",
    "perturbed_sample, original_sample = adversary.gradient_perturb(t=150, target=adversarial_target, y=y)\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(perturbed_sample[0].cpu()), cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(original_sample[0].cpu()), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_target = adversary.sample(y_adv)\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(adversarial_target[0].cpu()), cmap='gray')\n",
    "perturbed_sample, original_sample = adversary.gradient_descent_perturb(t=50, target=adversarial_target, scale=5, y=y)\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(perturbed_sample[0].cpu()), cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(original_sample[0].cpu()), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Guided Diffusion #####\n",
    "model_path = '../outputs/models/guided_fashion_mnist_diffusion_epoch_19.pt'\n",
    "\n",
    "# model params\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "data_shape = (28, 28)\n",
    "channels = 1\n",
    "dim_mults = (1, 2, 4, )\n",
    "T = 300\n",
    "\n",
    "unet = condUnet(\n",
    "    dim=data_shape[0],\n",
    "    channels=channels,\n",
    "    dim_mults=dim_mults,\n",
    "    num_classes=11,\n",
    ")\n",
    "unet.load_state_dict(torch.load(model_path))\n",
    "\n",
    "guided_diffusion = Guidance(\n",
    "    model=unet,\n",
    "    data_shape=data_shape,\n",
    "    T=T,\n",
    "    device=device,\n",
    "    noise_schedule='linear'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the adversary\n",
    "adversary = GuidedAdversary(\n",
    "    data_shape=data_shape,\n",
    "    diffusion_model=guided_diffusion,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample unperturbed image from the adversary\n",
    "y = torch.tensor([0]).to(device)\n",
    "w = 1\n",
    "y_adv = torch.tensor([1]).to(device)\n",
    "x = adversary.sample(y, w)\n",
    "plt.imshow(reverse_transform(x[0].cpu()), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample gaussian perturbed image from the adversary\n",
    "perturbed_sample, original_sample = adversary.gaussian_perturb(t=150, y=y, w=w)\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(perturbed_sample[0].cpu()), cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(original_sample[0].cpu()), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_target = adversary.sample(y_adv, w=w)\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(adversarial_target[0].cpu()), cmap='gray')\n",
    "perturbed_sample, original_sample = adversary.gradient_perturb(t=150, target=adversarial_target, y=y, w=w)\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(perturbed_sample[0].cpu()), cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(reverse_transform(original_sample[0].cpu()), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
