{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "os.chdir('../src')\n",
    "\n",
    "from models.diffusion import Diffusion, CondDiffusion\n",
    "from models.unet import Unet\n",
    "from models.condunet import condUnet\n",
    "\n",
    "reverse_transform = transforms.Compose([transforms.Lambda(lambda x: (x+1)/2), transforms.ToPILImage()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../outputs/models/fashion_mnist_diffusion_epoch_9.pt'\n",
    "\n",
    "# model params\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "data_shape = (28, 28)\n",
    "channels = 1\n",
    "dim_mults = (1, 2, 4, )\n",
    "T = 300\n",
    "\n",
    "unet = Unet(\n",
    "    dim=data_shape[0],\n",
    "    channels=channels,\n",
    "    dim_mults=dim_mults,\n",
    ")\n",
    "unet.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model = Diffusion(\n",
    "    model=unet,\n",
    "    data_shape=data_shape,\n",
    "    T=T,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples\n",
    "sample = model.sample().squeeze(0)\n",
    "sample = reverse_transform(sample)\n",
    "plt.imshow(sample, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../outputs/models/cond_mnist_diffusion_epoch_2.pt'\n",
    "\n",
    "# model params\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "data_shape = (28, 28)\n",
    "channels = 1\n",
    "dim_mults = (1, 2, 4, )\n",
    "T = 300\n",
    "\n",
    "net = condUnet(\n",
    "    dim=data_shape[0],\n",
    "    channels=channels,\n",
    "    dim_mults=dim_mults,\n",
    "    num_classes=10,\n",
    ")\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model = CondDiffusion(\n",
    "    model=net,\n",
    "    data_shape=data_shape,\n",
    "    T=T,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples\n",
    "label = torch.tensor([2]).to(device)\n",
    "sample = model.sample(label).squeeze(0)\n",
    "sample = reverse_transform(sample)\n",
    "plt.imshow(sample, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
